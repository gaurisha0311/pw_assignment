{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee811a45-354b-4e6a-b1bd-3f2b6b7c525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nObject Classification:\\n\\nDefinition: Object classification involves assigning a label or category to an entire image or a specific region\\nwithin an image.\\nExample: Classifying an image as containing a cat or a dog.\\nOutput: Single label or category for the entire image or region.\\nObject Detection:\\n\\nDefinition: Object detection involves locating and identifying multiple objects within an image. It provides\\ninformation about both the presence and location of objects.\\nExample: Identifying and localizing multiple instances of cats and dogs in an image.\\nOutput: Coordinates (bounding box) and class labels for each detected object.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1(a)\n",
    "'''\n",
    "Object Classification:\n",
    "\n",
    "Definition: Object classification involves assigning a label or category to an entire image or a specific region\n",
    "within an image.\n",
    "Example: Classifying an image as containing a cat or a dog.\n",
    "Output: Single label or category for the entire image or region.\n",
    "Object Detection:\n",
    "\n",
    "Definition: Object detection involves locating and identifying multiple objects within an image. It provides\n",
    "information about both the presence and location of objects.\n",
    "Example: Identifying and localizing multiple instances of cats and dogs in an image.\n",
    "Output: Coordinates (bounding box) and class labels for each detected object.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba28ba1-5759-4742-889e-375861f2b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImage data can be considered structured when it is preprocessed or represented in a way that preserves spatial\\nrelationships between pixels.\\nTechniques such as image segmentation or converting images to structured formats like tensors maintain the\\nstructured nature of image data.\\nThis structured representation enables the use of convolutional operations in neural networks to capture spatial\\nfeatures.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3(a)\n",
    "'''\n",
    "Image data can be considered structured when it is preprocessed or represented in a way that preserves spatial\n",
    "relationships between pixels.\n",
    "Techniques such as image segmentation or converting images to structured formats like tensors maintain the\n",
    "structured nature of image data.\n",
    "This structured representation enables the use of convolutional operations in neural networks to capture spatial\n",
    "features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eceec659-f1b5-430a-a6a0-840cb828c0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCNNs employ convolutional layers to capture local features like edges, textures, \\nand spatial hierarchies, enabling image understanding and classification.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4(a)\n",
    "'''\n",
    "CNNs employ convolutional layers to capture local features like edges, textures, \n",
    "and spatial hierarchies, enabling image understanding and classification.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e153cb6-45c6-45b2-85a5-480ccd755663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFlattening an image involves converting a two-dimensional array (image) into a one-dimensional array.\\nThis process is common in traditional Artificial Neural Networks (ANNs) where each pixel is treated as a separate \\ninput feature.\\nLoss of spatial information occurs, making ANNs less suitable for tasks where spatial relationships are crucial.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5(a)\n",
    "'''\n",
    "Flattening an image involves converting a two-dimensional array (image) into a one-dimensional array.\n",
    "This process is common in traditional Artificial Neural Networks (ANNs) where each pixel is treated as a separate \n",
    "input feature.\n",
    "Loss of spatial information occurs, making ANNs less suitable for tasks where spatial relationships are crucial.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d878f46-fbb6-4d24-b3ed-cb02b502d957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe MNIST dataset's simplicity, small size,\\nand clear features make CNNs unnecessary. Dense layers can effectively capture patterns for image classification.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6(a)\n",
    "'''\n",
    "The MNIST dataset's simplicity, small size,\n",
    "and clear features make CNNs unnecessary. Dense layers can effectively capture patterns for image classification.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfbe55-529b-4335-9874-c57ab42b7eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
