{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad098ac5-a38b-4b66-ad69-32f63663fd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPooling in Convolutional Neural Networks (CNNs) serves the purpose of \\ndownsampling feature maps, reducing the spatial dimensions of the input, and consequently decreasing the \\ncomputational load.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "#1\n",
    "'''\n",
    "Pooling in Convolutional Neural Networks (CNNs) serves the purpose of \n",
    "downsampling feature maps, reducing the spatial dimensions of the input, and consequently decreasing the \n",
    "computational load.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21bf8ef-e8e5-40d7-bd0a-0fc68ab58ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMax Pooling:\\n\\nInvolves selecting the maximum value from a group of neighboring pixels in the input.\\nEmphasizes the most prominent features, providing stronger activation to the most significant information in the \\nlocal region.\\nAverage Pooling:\\n\\nInvolves taking the average of the values in a group of neighboring pixels.\\nProvides a more smoothed representation of features and is less sensitive to outliers.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "'''\n",
    "Max Pooling:\n",
    "\n",
    "Involves selecting the maximum value from a group of neighboring pixels in the input.\n",
    "Emphasizes the most prominent features, providing stronger activation to the most significant information in the \n",
    "local region.\n",
    "Average Pooling:\n",
    "\n",
    "Involves taking the average of the values in a group of neighboring pixels.\n",
    "Provides a more smoothed representation of features and is less sensitive to outliers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e5ccdd-bc8d-493e-b584-b4fd53b55d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPadding is the process of adding extra pixels around the input image or \\nfeature map. Its significance lies in preventing the reduction in spatial dimensions during convolutional\\noperations. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "'''\n",
    "Padding is the process of adding extra pixels around the input image or \n",
    "feature map. Its significance lies in preventing the reduction in spatial dimensions during convolutional\n",
    "operations. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b513bd-8b6d-48b4-b676-f8b208781832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nZero-padding (Zer0-padding): Adding zero-value pixels around the input.\\nValid-padding: No padding is added, which may result in spatial dimension reduction.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "'''\n",
    "Zero-padding (Zer0-padding): Adding zero-value pixels around the input.\n",
    "Valid-padding: No padding is added, which may result in spatial dimension reduction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003668f3-04e9-4b59-b6f1-b4c57bd30468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConvolutional Layers: Detect features like edges and textures.\\nSubsampling (Pooling) Layers: Downsample and reduce spatial dimensions.\\nFully Connected Layers: Classify high-level features.\\nOutput Layer: Produces final class probabilities using a softmax activation.\\nAdvantages and Limitations:\\n\\nAdvantages: LeNet-5 introduced the concept of convolutional neural networks, which is crucial for image recognition. \\nIt is lightweight and computationally efficient.\\nLimitations: May struggle with complex datasets due to its simplicity and shallow architecture.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "#1\n",
    "'''\n",
    "Convolutional Layers: Detect features like edges and textures.\n",
    "Subsampling (Pooling) Layers: Downsample and reduce spatial dimensions.\n",
    "Fully Connected Layers: Classify high-level features.\n",
    "Output Layer: Produces final class probabilities using a softmax activation.\n",
    "Advantages and Limitations:\n",
    "\n",
    "Advantages: LeNet-5 introduced the concept of convolutional neural networks, which is crucial for image recognition. \n",
    "It is lightweight and computationally efficient.\n",
    "Limitations: May struggle with complex datasets due to its simplicity and shallow architecture.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4848413-1000-4288-84c3-b49ed7117f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdvantages: LeNet-5 introduced the concept of convolutional neural networks, which is crucial for image recognition. \\nIt is lightweight and computationally efficient.\\nLimitations: May struggle with complex datasets due to its simplicity and shallow architecture.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "'''\n",
    "Advantages: LeNet-5 introduced the concept of convolutional neural networks, which is crucial for image recognition. \n",
    "It is lightweight and computationally efficient.\n",
    "Limitations: May struggle with complex datasets due to its simplicity and shallow architecture.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7a6a1c-8129-4df4-a871-5de06595b414",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#4\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define LeNet-5 architecture\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#4\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define LeNet-5 architecture\n",
    "def lenet5():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional + Activation + Pooling\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Layer 2: Convolutional + Activation + Pooling\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Layer 3: Fully Connected + Activation\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "    # Layer 4: Fully Connected + Activation\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "    # Output layer: Fully Connected with softmax activation\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load and preprocess your dataset (e.g., MNIST)\n",
    "# Replace this with your dataset loading and preprocessing code\n",
    "\n",
    "# Example: MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Build and compile the model\n",
    "model = lenet5()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805dc7e6-c7e4-47ee-99cc-0005244c6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.26.2-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.5/186.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.26.2 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 opt-einsum-3.3.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.35.0 termcolor-2.4.0 werkzeug-3.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed00803e-ff41-4365-948c-375ab32f33ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 9s 8ms/step - loss: 0.2396 - accuracy: 0.9280 - val_loss: 0.1021 - val_accuracy: 0.9700\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0731 - accuracy: 0.9770 - val_loss: 0.0502 - val_accuracy: 0.9837\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0531 - accuracy: 0.9830 - val_loss: 0.0485 - val_accuracy: 0.9841\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 0.0414 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0470 - val_accuracy: 0.9842\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0355 - val_accuracy: 0.9879\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0375 - val_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0325 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0346 - val_accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0419 - val_accuracy: 0.9878\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9878\n",
      "Test accuracy: 0.9878000020980835\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define LeNet-5 architecture\n",
    "def lenet5():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional + Activation + Pooling\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)))  # Adjusted input shape\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Layer 2: Convolutional + Activation + Pooling\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Layer 3: Fully Connected + Activation\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "    # Layer 4: Fully Connected + Activation\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "    # Output layer: Fully Connected with softmax activation\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load and preprocess your dataset (e.g., MNIST)\n",
    "# Replace this with your dataset loading and preprocessing code\n",
    "\n",
    "# Example: MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Build and compile the model\n",
    "model = lenet5()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576a5597-ffb8-4bec-bfbe-f828852938d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAlexNet is a pioneering deep convolutional neural network architecture designed for image classification. It won \\nthe ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012, marking a breakthrough in computer vision.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "#1\n",
    "'''\n",
    "AlexNet is a pioneering deep convolutional neural network architecture designed for image classification. It won \n",
    "the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012, marking a breakthrough in computer vision.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d437c7-83d1-4678-a095-74a6119ec480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDeep Architecture: AlexNet introduced a deep neural network with\\neight layers, consisting of five convolutional layers and three fully connected layers. This depth allowed the\\nmodel to learn hierarchical features.\\n\\nRectified Linear Unit (ReLU): AlexNet used the rectified linear unit as the activation function, replacing\\ntraditional activation functions like sigmoid or tanh. ReLU accelerates training by avoiding the vanishing \\ngradient problem.\\n\\nLocal Response Normalization (LRN): LRN was applied after the ReLU activation in some layers. It enhances the\\ncontrast of activated regions and promotes generalization.\\n\\nDropout: Dropout was employed as a regularization technique to prevent overfitting. It randomly drops connections \\nduring training, forcing the network to learn more robust features.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "'''\n",
    "Deep Architecture: AlexNet introduced a deep neural network with\n",
    "eight layers, consisting of five convolutional layers and three fully connected layers. This depth allowed the\n",
    "model to learn hierarchical features.\n",
    "\n",
    "Rectified Linear Unit (ReLU): AlexNet used the rectified linear unit as the activation function, replacing\n",
    "traditional activation functions like sigmoid or tanh. ReLU accelerates training by avoiding the vanishing \n",
    "gradient problem.\n",
    "\n",
    "Local Response Normalization (LRN): LRN was applied after the ReLU activation in some layers. It enhances the\n",
    "contrast of activated regions and promotes generalization.\n",
    "\n",
    "Dropout: Dropout was employed as a regularization technique to prevent overfitting. It randomly drops connections \n",
    "during training, forcing the network to learn more robust features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170a79e9-f6ad-4498-a629-c1fee79ac113",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 2, 2, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Output layer: Fully Connected with softmax activation\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 34\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file8yhchfpz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 2, 2, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Define AlexNet architecture\n",
    "def alexnet():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional + Activation + Pooling\n",
    "    model.add(layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(32, 32, 3)))  # Adjusted input shape\n",
    "    model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "    # ... (Rest of the architecture remains the same)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "model = alexnet()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Output layer: Fully Connected with softmax activation\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55638b0-00bc-4b42-97aa-ab1fa7a96f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
