{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d375c6-2014-4692-ab39-457b71ee6b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhe main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type \\nof data they are suitable for:\\n\\nBernoulli Naive Bayes is suitable for binary feature data, where features represent the presence or absence of a\\nparticular characteristic.\\nMultinomial Naive Bayes is suitable for data with discrete features that can represent counts or frequencies.\\nIt's commonly used in text classification where features represent word counts or frequencies.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "'''\n",
    "he main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type \n",
    "of data they are suitable for:\n",
    "\n",
    "Bernoulli Naive Bayes is suitable for binary feature data, where features represent the presence or absence of a\n",
    "particular characteristic.\n",
    "Multinomial Naive Bayes is suitable for data with discrete features that can represent counts or frequencies.\n",
    "It's commonly used in text classification where features represent word counts or frequencies.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70eb0bba-7342-4315-9c1f-84f6cd39e0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBernoulli Naive Bayes handles missing values by ignoring them during training and classification. Since it works\\nwith binary features (presence or absence), missing values can simply be treated as the absence of a feature.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "'''\n",
    "Bernoulli Naive Bayes handles missing values by ignoring them during training and classification. Since it works\n",
    "with binary features (presence or absence), missing values can simply be treated as the absence of a feature.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e8b373-6944-4a51-86f9-843bcd771e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGaussian Naive Bayes can indeed be used for multi-class classification. It's suitable for continuous data where\\nfeatures follow a Gaussian distribution. In multi-class classification, it can predict the probability \\nof an instance belonging to each class and choose the class with the highest probability as the predicted class.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4\n",
    "'''\n",
    "Gaussian Naive Bayes can indeed be used for multi-class classification. It's suitable for continuous data where\n",
    "features follow a Gaussian distribution. In multi-class classification, it can predict the probability \n",
    "of an instance belonging to each class and choose the class with the highest probability as the predicted class.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6bc5e5-dd13-42b0-9c38-9d987b3a7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
