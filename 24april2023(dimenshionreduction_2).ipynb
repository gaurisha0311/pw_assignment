{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3dbdcf-c378-4ea7-9629-f1a44321962d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn PCA, a projection is the transformation of data onto a lower-dimensional subspace.\\nIt involves finding a set of basis vectors that capture the maximum variance in the data.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "'''\n",
    "In PCA, a projection is the transformation of data onto a lower-dimensional subspace.\n",
    "It involves finding a set of basis vectors that capture the maximum variance in the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280c8a72-f786-483f-934c-c30c67b93b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA aims to find the projection direction (principal components) that maximizes the variance of the data.\\nIt involves solving an eigenvalue problem to find the eigenvectors (principal components) corresponding to the \\nlargest eigenvalues of the covariance matrix.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "'''\n",
    "PCA aims to find the projection direction (principal components) that maximizes the variance of the data.\n",
    "It involves solving an eigenvalue problem to find the eigenvectors (principal components) corresponding to the \n",
    "largest eigenvalues of the covariance matrix.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2448645e-5057-4546-89f8-97a8a05c32ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCovariance matrices quantify the relationships between different dimensions in the data.\\nIn PCA, the eigenvectors of the covariance matrix represent the principal components\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "'''\n",
    "Covariance matrices quantify the relationships between different dimensions in the data.\n",
    "In PCA, the eigenvectors of the covariance matrix represent the principal components\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bdd244-82ed-4739-8f00-3e7a508c30a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA can be used to identify and retain the most informative features by selecting the corresponding principal \\ncomponents.\\nBenefits include reduced dimensionality, elimination of redundant features, and focus on features contributing \\nmost to the variance.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5\n",
    "'''\n",
    "PCA can be used to identify and retain the most informative features by selecting the corresponding principal \n",
    "components.\n",
    "Benefits include reduced dimensionality, elimination of redundant features, and focus on features contributing \n",
    "most to the variance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2df3c1c-9394-4908-81e0-8ef5fd23a67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDimensionality Reduction: Reducing the number of features while retaining important information.\\nNoise Reduction: Eliminating noise or irrelevant information.\\nVisualization: Projecting high-dimensional data onto a lower-dimensional space for visualization.\\nFeature Selection: Identifying and selecting important features.\\nData Compression: Efficient representation of data.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6\n",
    "'''\n",
    "Dimensionality Reduction: Reducing the number of features while retaining important information.\n",
    "Noise Reduction: Eliminating noise or irrelevant information.\n",
    "Visualization: Projecting high-dimensional data onto a lower-dimensional space for visualization.\n",
    "Feature Selection: Identifying and selecting important features.\n",
    "Data Compression: Efficient representation of data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b5d4e9-65b1-4eb1-8e54-23d33b77b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSpread refers to the range of values in a dataset.\\nVariance measures the average squared deviation from the mean.\\nIn PCA, spread is related to the eigenvalues of the covariance \\nmatrix, with higher eigenvalues indicating greater variance.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7\n",
    "'''\n",
    "Spread refers to the range of values in a dataset.\n",
    "Variance measures the average squared deviation from the mean.\n",
    "In PCA, spread is related to the eigenvalues of the covariance \n",
    "matrix, with higher eigenvalues indicating greater variance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0faf3b71-cc1e-4d2a-b917-aa0432785e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA identifies principal components by finding the directions (eigenvectors) along which the spread (variance)\\nof the data is maximized.\\nPrincipal components are ordered by the amount of variance they capture.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q8\n",
    "'''\n",
    "PCA identifies principal components by finding the directions (eigenvectors) along which the spread (variance)\n",
    "of the data is maximized.\n",
    "Principal components are ordered by the amount of variance they capture.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de369e-505e-4b07-a639-911ea747e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q9\n",
    "'''\n",
    "PCA identifies principal components based on the directions of maximum variance.\n",
    "Dimensions with high variance contribute more to the principal components.\n",
    "PCA automatically prioritizes dimensions with high variance, effectively handling imbalances in variance.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
